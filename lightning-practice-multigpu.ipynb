{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7351581,"sourceType":"datasetVersion","datasetId":4269382},{"sourceId":7465053,"sourceType":"datasetVersion","datasetId":4345260}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import warnings\n#warnings.filterwarnings(\"ignore\")\n\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import WandbLogger\n\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\nwandb.login(key = api_key)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split, DataLoader\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning import seed_everything\n\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\nfrom PIL import Image\n\nimport os\nimport random\n\nseed_everything(4)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:16:17.448992Z","iopub.execute_input":"2024-02-15T23:16:17.449405Z","iopub.status.idle":"2024-02-15T23:16:17.959385Z","shell.execute_reply.started":"2024-02-15T23:16:17.449379Z","shell.execute_reply":"2024-02-15T23:16:17.958473Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"no_action_path = list(Path(\"/kaggle/input/chart-multi/0\").glob('*.png'))\nbuy_path = list(Path(\"/kaggle/input/chart-multi/1\").glob('*.png'))\nsell_path = list(Path(\"/kaggle/input/chart-multi/2\").glob('*.png'))\n\nnum_images = 3\nno_action_samples = random.sample(no_action_path, num_images)\nbuy_samples = random.sample(buy_path, num_images)\nsell_samples = random.sample(sell_path, num_images)\n\nfig = plt.figure(figsize=(20,15))\nimages = []\nlabels = []\n\nfor no_action, buy, sell in zip(no_action_samples, buy_samples, sell_samples):\n    with open(no_action, 'rb') as f_no_action, \\\n         open(buy, 'rb') as f_buy, \\\n         open(sell, 'rb') as f_sell:\n        no_action_img, buy_img, sell_img = Image.open(f_no_action), Image.open(f_buy), Image.open(f_sell)\n        no_action_img, buy_img, sell_img = no_action_img.convert(\"RGB\"), buy_img.convert(\"RGB\"), sell_img.convert(\"RGB\")\n        images.extend([no_action_img, buy_img, sell_img])\n        labels.extend(['no-action', 'buy', 'sell'])\n        \n\nfor i, (label, image) in enumerate(zip(labels, images), start=1):\n    ax = plt.subplot(num_images, 3, i)\n    ax.axis('off')\n    ax.set_title(label)\n    ax.imshow(image)\n    \nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:16:17.960406Z","iopub.execute_input":"2024-02-15T23:16:17.960892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Charts_DataModule(pl.LightningDataModule):\n    def __init__(self, batch_size=32, image_size=224, seed=42):\n        super().__init__()\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.seed = seed\n        \n    def prepare_data(self):\n        # we might need to implement this for combining all the augmented data sets into a single folder\n        pass\n    \n    def setup(self, stage=None):\n        # Define transformations\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n        ])       \n    \n        dataset_train = torchvision.datasets.ImageFolder(\"/kaggle/input/test-multi-2024\", transform=transform)\n        self.train_dataset, self.val_dataset = random_split(dataset_train, (0.8, 0.20), generator=torch.Generator().manual_seed(self.seed))\n    \n        dataset_test = torchvision.datasets.ImageFolder(\"/kaggle/input/test-multi-2024\", transform=transform)\n        self.test_dataset = dataset_test\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n    \n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=os.cpu_count())\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=os.cpu_count())\n      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm  # Assuming you're using the timm library for ViT\n\nclass ViT_LightningModule(pl.LightningModule):\n    def __init__(self, num_classes: int, learning_rate=2e-4, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model('vit_base_patch16_224', pretrained=pretrained, num_classes=num_classes)\n        self.learning_rate = learning_rate\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.save_hyperparameters()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = self.loss_fn(outputs, labels)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def evaluate(self, batch, stage=None):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = self.loss_fn(outputs, labels)\n        \n        _, predicted_labels = torch.max(outputs, 1)\n        correct_predictions = (predicted_labels == labels).sum().item()\n        total_predictions = labels.size(0)\n        acc = correct_predictions / total_predictions\n        \n        if stage:\n            self.log(f'{stage}_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n            self.log(f'{stage}_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n            \n    def validation_step(self, batch, batch_idx):\n        self.evaluate(batch, \"val\")\n    \n    def test_step(self, batch, batch_idx):\n        self.evaluate(batch, \"test\")","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:16:28.761031Z","iopub.execute_input":"2024-02-15T23:16:28.761840Z","iopub.status.idle":"2024-02-15T23:16:29.144121Z","shell.execute_reply.started":"2024-02-15T23:16:28.761805Z","shell.execute_reply":"2024-02-15T23:16:29.143123Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Training the model\nos.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n\ntrainer = pl.Trainer(\n    default_root_dir=\"/kaggle/working\",\n    accelerator=\"auto\",\n    devices=1,\n    max_epochs=2,\n    #strategy=\"ddp_notebook\",\n    logger = WandbLogger(name = \"test\"),\n    log_every_n_steps=5,\n    callbacks=[\n        ModelCheckpoint(\n            save_weights_only=True,\n            mode=\"max\",\n            monitor=\"val_acc\",\n            dirpath=\"/kaggle/working/checkpoints\",\n            filename=\"{epoch}-{val_loss:.2f}-{val_acc:.2f}\"\n        ),\n        EarlyStopping(\n            monitor=\"val_acc\",\n            mode=\"max\",\n            patience=5,\n            verbose=False\n        )\n    ],\n)\n\ndm = Charts_DataModule(batch_size=32, image_size=224, seed=0)\ndm.setup()\n\ncheckpoints = list(Path(\"/kaggle/working/checkpoints\").glob(\"*.ckpt\"))\nif checkpoints:\n    print(\"Loading model from checkpoint...\")\n    checkpoint = max(checkpoints, key=lambda c: c.stat().st_ctime) # Grab the most recent checkpoint\n    model = ViT_LightningModule.load_from_checkpoint(str(checkpoint.resolve()))\nelse:\n    print(\"Training...\")\n    model = ViT_LightningModule(num_classes=3, pretrained=True)\n    trainer.fit(model, datamodule=dm)\n    # Load best checkpoint after training\n    model = ViT_LightningModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:26:45.821167Z","iopub.execute_input":"2024-02-15T23:26:45.821846Z","iopub.status.idle":"2024-02-15T23:26:48.082194Z","shell.execute_reply.started":"2024-02-15T23:26:45.821816Z","shell.execute_reply":"2024-02-15T23:26:48.081161Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Loading model from checkpoint...\n","output_type":"stream"}]},{"cell_type":"code","source":"#trainer.validate(model, datamodule=dm)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:26:56.648257Z","iopub.execute_input":"2024-02-15T23:26:56.649067Z","iopub.status.idle":"2024-02-15T23:27:04.059542Z","shell.execute_reply.started":"2024-02-15T23:26:56.649033Z","shell.execute_reply":"2024-02-15T23:27:04.058242Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc63c26414b84ce490161498571ae837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m      val_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9651415944099426    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m     val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1775885373353958    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">       val_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9651415944099426     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">      val_loss_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1775885373353958     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'val_loss_epoch': 0.1775885373353958, 'val_acc_epoch': 0.9651415944099426}]"},"metadata":{}}]},{"cell_type":"code","source":"#trainer.test(model, datamodule=dm)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T23:20:02.677419Z","iopub.execute_input":"2024-02-15T23:20:02.678158Z","iopub.status.idle":"2024-02-15T23:20:32.530707Z","shell.execute_reply.started":"2024-02-15T23:20:02.678122Z","shell.execute_reply":"2024-02-15T23:20:32.529513Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0772da2336344e9f9140d6aa6371054e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9438642263412476    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26019471883773804   \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9438642263412476     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26019471883773804    </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'test_loss_epoch': 0.26019471883773804,\n  'test_acc_epoch': 0.9438642263412476}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}